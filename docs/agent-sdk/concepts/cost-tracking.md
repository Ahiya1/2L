---
title: "Cost Tracking and Optimization"
last_updated: "2025-10-13"
sdk_version: "1.2.0"
sdk_version_range: "1.0.0+"
status: "stable"
language: "cross-language"
difficulty: "beginner"
prerequisites:
  - "Read [Agent SDK Overview](../overview.md)"
  - "Completed setup for [TypeScript](../typescript/setup.md) or [Python](../python/setup.md)"
next_steps:
  - "Set up [Hooks](./hooks.md) for token tracking"
  - "Monitor [Session](./sessions.md) costs"
  - "Optimize prompts based on token usage"
related_guides:
  - ../typescript/options.md
  - ./sessions.md
tags:
  - cost
  - tokens
  - optimization
  - monitoring
---

# Cost Tracking and Optimization

## Overview

The Agent SDK provides built-in token usage tracking to help you monitor and control API costs. Every agent interaction with Claude consumes tokens (both input and output), which translate directly to API costs. Understanding token consumption patterns, implementing tracking, and optimizing for efficiency are essential for cost-effective agent deployments, especially in production environments with high traffic or long-running conversations.

## When to Use

Implement cost tracking when:
- Deploying agents to production with significant traffic
- Building multi-user applications with per-user billing
- Operating under budget constraints
- Monitoring resource usage for optimization
- Debugging unexpectedly high API costs
- Implementing usage quotas or rate limiting

Track costs at different levels:
- **Per-request:** Individual query cost analysis
- **Per-session:** Cumulative cost across conversation
- **Per-user:** User-level usage and billing
- **Per-application:** Overall application cost monitoring
- **Per-feature:** Cost attribution to specific features

## Core Principles

### Token-Based Pricing Model

Claude API pricing is based on tokens consumed:

**Input Tokens:** Text sent to Claude (prompts, system messages, conversation history, tool descriptions)

**Output Tokens:** Text generated by Claude (responses, reasoning, tool calls)

**Pricing Tiers:**
- Different models have different per-token costs
- Input tokens typically cheaper than output tokens
- Costs published at: https://anthropic.com/pricing

**Example Calculation:**
```
Request:
- Input tokens: 1,000
- Output tokens: 500

Cost (Claude Sonnet):
- Input: 1,000 tokens × $0.003 per 1K = $0.003
- Output: 500 tokens × $0.015 per 1K = $0.0075
- Total: $0.0105 per request
```

### Token Counting

Tokens are subword units, not words:
- English: ~1 token per 0.75 words
- Code: Varies by language and structure
- Whitespace and punctuation consume tokens
- Special characters may use multiple tokens

**Approximate token counts:**
- "Hello world" ≈ 2 tokens
- Average sentence ≈ 15-30 tokens
- Page of text ≈ 500-1000 tokens
- Small file ≈ 1000-5000 tokens

The SDK provides exact token counts after each request.

### Cumulative Costs

In stateful sessions, costs accumulate:
- Each turn includes full conversation history
- History grows with each exchange
- Token count increases linearly with conversation length
- Long conversations become expensive

**Example:**
```
Turn 1: 1,000 tokens (prompt only)
Turn 2: 2,500 tokens (prompt + turn 1 + new input)
Turn 3: 4,000 tokens (prompt + turn 1 + turn 2 + new input)
...
Turn 10: 20,000+ tokens
```

## Common Patterns

### Per-Request Tracking

Capture token usage for each API call:

**Data to track:**
- Request timestamp
- Input token count
- Output token count
- Total cost (calculated)
- Request parameters (model, temperature, etc.)
- User/session identifier

**Storage options:**
- Structured logs (JSON logs to file or logging service)
- Time-series database (InfluxDB, Prometheus)
- Analytics platform (Google Analytics, Mixpanel)
- Application database

**Use cases:**
- Debugging high-cost requests
- Identifying optimization opportunities
- User usage reporting
- Cost attribution

### Session-Level Tracking

Monitor cumulative costs across conversations:

**Data to track:**
- Session ID
- Total tokens consumed
- Total cost
- Request count
- Session duration
- User identifier

**Aggregation:**
- Sum token counts across all session requests
- Calculate running total cost
- Track cost velocity (cost per minute)
- Identify expensive sessions

**Use cases:**
- Per-session billing
- Session cost limits
- Conversation efficiency analysis
- User behavior insights

### User-Level Tracking

Aggregate usage per user for billing and quotas:

**Data to track:**
- User ID
- Total tokens (lifetime or period)
- Total cost
- Session count
- Time period (daily, monthly, etc.)

**Quota enforcement:**
- Set token limits per user
- Set cost limits per user
- Implement soft limits (warnings) and hard limits (blocking)
- Reset quotas periodically

**Use cases:**
- User billing and invoicing
- Freemium tier management
- Abuse prevention
- Fair usage policies

### Real-Time Cost Monitoring

Track costs as they happen:

**Metrics to monitor:**
- Requests per second
- Tokens per second
- Cost per second
- Cost per hour/day
- Cumulative daily cost

**Alerting:**
- Alert when cost exceeds threshold
- Alert on unusual cost spikes
- Alert on quota approaching limit
- Alert on error rate increases

**Dashboards:**
- Real-time cost graphs
- Cost breakdown by feature/user
- Comparison to historical data
- Budget vs actual spending

## Best Practices

### Track All Requests

Never skip cost tracking:
- Track successful and failed requests
- Track development and production usage
- Include all environments in monitoring
- Don't rely on memory; persist tracking data

### Implement Cost Alerts

Set up proactive notifications:
- Daily cost threshold alerts
- Hourly spike detection
- User quota warnings
- Budget approaching limit

### Monitor Cost Trends

Look for patterns over time:
- Daily/weekly cost trends
- Seasonal variations
- Feature launch impact
- User growth correlation

### Optimize Based on Data

Use tracking data to guide optimization:
- Identify highest-cost operations
- Find inefficient prompts or workflows
- Discover opportunities for caching
- Detect token-heavy edge cases

### Budget Allocation

Plan and allocate budgets:
- Set per-feature budgets
- Allocate per-user quotas
- Reserve budget for spikes
- Plan for growth

### Expose Usage to Users

Help users understand their usage:
- Show token counts in UI
- Display estimated costs
- Provide usage history
- Offer cost-saving tips

## Optimization Techniques

### Prompt Engineering

Reduce input token costs:
- Use concise, clear prompts (avoid verbosity)
- Remove unnecessary examples
- Use system prompts efficiently
- Avoid redundant context

**Before:** "Please carefully analyze the following code and tell me what you think about it, including any issues you might find, improvements that could be made, and overall assessment of the code quality..."

**After:** "Analyze this code for issues and improvements:"

### Conversation History Pruning

Limit context window usage:
- Keep only recent messages (e.g., last 10 turns)
- Summarize old conversation segments
- Remove tool outputs after agent processes them
- Prune system messages when not needed

**Strategies:**
- Sliding window: Keep N most recent messages
- Importance-based: Keep critical messages, remove filler
- Summarization: Condense old context into summaries
- Smart pruning: Remove based on semantic relevance

### Response Length Control

Limit output tokens:
- Use max_tokens parameter to cap output
- Request concise responses in prompts
- Use structured output formats (JSON) instead of prose
- Stop generation early when requirements met

**Prompt additions:**
- "Be concise."
- "Answer in under 50 words."
- "Use bullet points, not paragraphs."

### Caching Strategies

Avoid redundant API calls:
- Cache responses for identical queries
- Cache tool descriptions (don't send every request)
- Cache system prompts
- Implement time-based cache invalidation

**Cacheable items:**
- Static tool definitions
- Unchanging context documents
- FAQ-style responses
- Expensive computations

### Streaming for Early Termination

Use streaming mode to stop generation early:
- Monitor streamed output in real-time
- Terminate when sufficient information received
- Useful for search/retrieval tasks
- Reduces output token waste

**Pattern:**
```
Start streaming response
Monitor output
If requirement met:
  Stop stream (save remaining tokens)
Else:
  Continue to completion
```

### Model Selection

Choose appropriate models for tasks:
- Use smaller models for simple tasks
- Reserve large models for complex reasoning
- Consider cost-performance trade-offs
- Test with different models

**Model tiers:**
- Haiku: Fast, inexpensive, simple tasks
- Sonnet: Balanced, most use cases
- Opus: Highest capability, highest cost

### Batching Requests

Combine multiple operations when possible:
- Batch independent queries
- Use multi-tool agents to accomplish multiple goals in one request
- Aggregate user requests before processing
- Balance latency vs cost

## Performance Considerations

### Tracking Overhead

Cost tracking adds minimal overhead:
- Token counts provided by API (no extra cost)
- Local calculation and logging: <1ms
- Database writes: 5-50ms (async recommended)
- Metric aggregation: negligible

Use async logging to avoid blocking requests.

### Storage Requirements

Plan for tracking data storage:
- Per-request data: ~100-500 bytes
- 1 million requests ≈ 100-500 MB
- Implement data retention policies
- Archive old data to cold storage

### Real-Time Processing

For high-traffic applications:
- Use message queues (Kafka, RabbitMQ)
- Process tracking data asynchronously
- Aggregate in background workers
- Use streaming analytics platforms

### Cost of Tracking

Balance tracking granularity with storage/processing costs:
- Full request logs: Most expensive, most detailed
- Aggregated metrics: Cheap, less granular
- Sampled requests: Balanced approach
- Choose based on requirements

## Security Considerations

### Protect Usage Data

Usage data can be sensitive:
- Contains user activity patterns
- May include business metrics
- Can reveal feature usage
- Encrypt at rest and in transit

### Access Control

Limit who can view usage data:
- Implement role-based access
- Separate user-facing and admin dashboards
- Audit access to cost data
- Anonymize where possible

### Privacy Compliance

Respect user privacy:
- Don't log conversation content unnecessarily
- Implement data retention limits
- Allow users to request data deletion
- Comply with GDPR, CCPA, etc.

### Quota Enforcement

Securely enforce usage limits:
- Validate quotas server-side
- Don't trust client-side checks
- Handle quota bypass attempts
- Log quota violations

## Related Documentation

**Implementation:**
- [TypeScript Configuration](../typescript/options.md) - Enabling cost tracking in TypeScript
- [Python Configuration](../python/options.md) - Cost tracking setup for Python

**Concepts:**
- [Sessions](./sessions.md) - Understanding session costs and optimization
- [Hooks](./hooks.md) - Using hooks for cost tracking
- [Tools](./tools.md) - Tool usage impact on costs

**Examples:**
- [Stateful Chatbot](../examples/stateful-chatbot.md) - Tracking conversation costs
- [Web API Agent](../examples/web-api-agent.md) - Per-request cost monitoring
